name: Upload new SQL files to S3

on:
  workflow_dispatch:
    inputs:
      s3_bucket:
        description: 'Enter the S3 bucket name (optional)'
        required: false
        type: string

jobs:
  upload-new-sql-files:
    runs-on: ubuntu-latest

    env:
      AWS_REGION: us-east-1
      DEFAULT_BUCKET: ${{ vars.DEFAULT_BUCKET }}  # Set this in repository variables

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Important: fetch full history

      - name: Set up AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Determine bucket name
        id: bucket
        run: |
          BUCKET_INPUT="${{ github.event.inputs.s3_bucket }}"
          if [[ -z "$BUCKET_INPUT" ]]; then
            echo "Using default bucket: $DEFAULT_BUCKET"
            echo "bucket_name=$DEFAULT_BUCKET" >> "$GITHUB_OUTPUT"
          else
            echo "Using input bucket: $BUCKET_INPUT"
            echo "bucket_name=$BUCKET_INPUT" >> "$GITHUB_OUTPUT"
          fi

      - name: Detect newly added files in sql/ folder
        id: detect
        run: |
          echo "Detecting new files in sql/..."

          # Get last 2 commits on the current branch
          COMMIT_RANGE=$(git log --format="%H" -2 | tac | paste -sd " " -)
          read PREV_COMMIT CURR_COMMIT <<< "$COMMIT_RANGE"

          echo "Previous commit: $PREV_COMMIT"
          echo "Current commit : $CURR_COMMIT"

          git diff --diff-filter=A --name-only  origin/dev...HEAD "$PREV_COMMIT" "$CURR_COMMIT" \
            | grep '^sql/' > added_files.txt || true

          echo "Detected files:"
          cat added_files.txt || echo "No files detected"

          if [[ -s added_files.txt ]]; then
            echo "files_changed=true" >> "$GITHUB_OUTPUT"
          else
            echo "files_changed=false" >> "$GITHUB_OUTPUT"
          fi

      - name: Upload new SQL files to S3
        if: steps.detect.outputs.files_changed == 'true'
        run: |
          BUCKET_NAME=${{ steps.bucket.outputs.bucket_name }}
          echo "Uploading to S3 bucket: $BUCKET_NAME"

          while IFS= read -r file; do
            echo "Uploading $file to s3://$BUCKET_NAME/$file"
            aws s3 cp "$file" "s3://$BUCKET_NAME/$file"
          done < added_files.txt
