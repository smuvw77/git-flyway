name: Upload new SQL files to S3

on:
  workflow_dispatch:
    inputs:
      s3_bucket:
        description: 'Enter the S3 bucket name'
        required: false
        type: string

jobs:
  upload-new-sql-files:
    runs-on: ubuntu-latest

    env:
      AWS_REGION: us-east-1
      DEFAULT_BUCKET: ${{ vars.DEFAULT_BUCKET }}  # Or use secrets.DEFAULT_BUCKET if private

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Important: Fetch full history for git diff

      - name: Set up AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Determine bucket name
        id: bucket
        run: |
          BUCKET_INPUT="${{ github.event.inputs.s3_bucket }}"
          if [[ -z "$BUCKET_INPUT" ]]; then
            echo "Using default bucket: $DEFAULT_BUCKET"
            echo "bucket_name=$DEFAULT_BUCKET" >> "$GITHUB_OUTPUT"
          else
            echo "Using input bucket: $BUCKET_INPUT"
            echo "bucket_name=$BUCKET_INPUT" >> "$GITHUB_OUTPUT"
          fi

      - name: Detect newly added files in sql/ folder
        id: detect
        run: |
          echo "Current SHA: ${{ github.sha }}"
          git log -1

          git fetch origin main  # Change to your actual default branch if needed

          # Try to get previous commit from current branch
          PREV_COMMIT=$(git rev-parse HEAD^)
          echo "Previous commit: $PREV_COMMIT"

          git diff --diff-filter=A --name-only "$PREV_COMMIT" ${{ github.sha }} | grep '^sql/' > added_files.txt || true

          echo "Newly added files in sql/:"
          cat added_files.txt || echo "None"

          if [[ -s added_files.txt ]]; then
            echo "files_changed=true" >> "$GITHUB_OUTPUT"
          else
            echo "files_changed=false" >> "$GITHUB_OUTPUT"
          fi

      - name: Upload new SQL files to S3
        if: steps.detect.outputs.files_changed == 'true'
        run: |
          BUCKET_NAME=${{ steps.bucket.outputs.bucket_name }}
          echo "Uploading to bucket: $BUCKET_NAME"

          while IFS= read -r file; do
            echo "Uploading $file to s3://$BUCKET_NAME/$file"
            aws s3 cp "$file" "s3://$BUCKET_NAME/$file"
          done < added_files.txt
