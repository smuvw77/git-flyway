name: Upload new SQL files to S3

on:
  workflow_dispatch:
    inputs:
      s3_bucket:
        description: 'Enter the S3 bucket name (optional)'
        required: false
        type: string

jobs:
  upload-new-sql-files:
    runs-on: ubuntu-latest

    env:
      AWS_REGION: us-east-1
      DEFAULT_BUCKET: ${{ vars.DEFAULT_BUCKET }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Determine bucket name
        id: bucket
        run: |
          BUCKET_INPUT="${{ github.event.inputs.s3_bucket }}"
          if [[ -z "$BUCKET_INPUT" ]]; then
            echo "Using default bucket: $DEFAULT_BUCKET"
            echo "bucket_name=$DEFAULT_BUCKET" >> "$GITHUB_OUTPUT"
          else
            echo "Using input bucket: $BUCKET_INPUT"
            echo "bucket_name=$BUCKET_INPUT" >> "$GITHUB_OUTPUT"
          fi

      - name: Detect new files in sql/ (manual-friendly)
        id: detect
        run: |
          echo "Detecting new files in sql/..."
          git fetch origin
          git diff --name-only origin/main...HEAD | grep '^sql/' > added_files.txt || true

          echo "Files found:"
          cat added_files.txt || echo "None"

          if [[ -s added_files.txt ]]; then
            echo "files_changed=true" >> "$GITHUB_OUTPUT"
          else
            echo "files_changed=false" >> "$GITHUB_OUTPUT"
          fi

      - name: Upload new SQL files to S3
        if: steps.detect.outputs.files_changed == 'true'
        run: |
          BUCKET_NAME=${{ steps.bucket.outputs.bucket_name }}
          echo "Uploading to bucket: $BUCKET_NAME"

          while IFS= read -r file; do
            echo "Uploading $file to s3://$BUCKET_NAME/$file"
            aws s3 cp "$file" "s3://$BUCKET_NAME/$file"
          done < added_files.txt
